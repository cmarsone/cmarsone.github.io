---
layout: post
title: Machine Learning fairness in medical problems - MEDI-FAIR challenge
---

#### Introduction

"Machine learning (ML) models are commonly used to support healthcare decisions that
profoundly affect patient’s lives. Thus, biased machine learning models can disadvantage minority
subpopulations and put their health at risk. New ML fairness methods are designed to mitigate these
risks, but how well do they really work? Help protect vulnerable subpopulations by solving a challenge to
stress-tests ML fairness methods on a series of benchmarks."

### Background: understanding the causality

Understanding the causal connections between variables is a key objective across various fields, including social, behavioral, natural, and physical sciences. In medical studies, comprehending the link between genetic or environmental factors and the onset or severity of a disease is crucial in developing prevention, diagnosis, and treatment strategies. The most recent fairness principles acknowledge the significance of causality, recognizing that integrating causality is essential in addressing fairness issues.

Randomized controlled trials (RCTs) are a well-established method of establishing causal relationships. RCTs involve assigning subjects randomly to either a test or control group and controlling the potential cause and effect factors in a controlled environment. RCTs are widely considered the best way to establish causal relationships since they minimize the risks of bias and confounding.

Confounding can arise when a third factor causes both the supposed exposure and outcome. In cases where this third factor is unknown, false assumptions about causal relationships can be made, or a weak causal relationship may be overestimated.

However, when RCTs are not feasible, causal relationships must be inferred using available observational data through causal discovery algorithms. However, reconstructing a causal graph from empirical observational data can be challenging as disentangling the true causal relationships from unknown confounding factors, mediators, and sample bias can be difficult.

### Goal

The objective of this challenge is to determine the causal direction between two variables, A and B. There are four possible scenarios: 
- A causes B
- B causes A
- A and B are both consequences of a common cause C
- A and B are independent.

For sake of simplicity, the last two scenarios are merged. Participants must provide a confidence score between negative and positive infinity. A positive score indicates that A causes B, while a negative score indicates that B causes A. The confidence score represents the level of confidence in the answer, with higher scores indicating stronger confidence. If the score is close to zero, it implies that A and B are independent or that A and B are both consequences of a common cause.

### Evaluation metric

In this context, we utilize the Receiver Operating Characteristic Curve's Area Under the Curve (ROC AUC) metric. ROC AUC is typically used in binary classification problems, but we adopt a one-vs-all approach for multiclass classification problems. We calculate two ROC AUC scores, one for the "A causes B" class, and the other for the "B causes A" class, creating a "forward" and "backward" score. We take the average of the two ROC AUCs as the final score.

![image](https://user-images.githubusercontent.com/109908559/223630609-1890c5e0-f494-4bbb-b55d-e2bd808581fa.png)

### Baseline solution

The baseline solution for causal discovery is the Additive Noise Model (ANM) from the causal discovery toolbox. This method assumes additive noise in the data and utilizes non-linear regression models to estimate the data generating process in both directions, calculates residuals, and tests their independence from the data. Although not advanced, ANM serves as a suitable initial point for developing more sophisticated solutions.

![image](https://user-images.githubusercontent.com/109908559/223629770-79f77af1-52bb-485e-82e6-f6c13c9a990f.png)

The research paper titled ["Additive Noise Models: Generating Non-Gaussian Systems with Correlated Errors"](https://proceedings.neurips.cc/paper/2008/file/f7664060cc52bc6f3d620bcedc94a4b6-Paper.pdf) introduces the Additive Noise Model (ANM) for generating non-Gaussian systems with correlated errors. It proposes a method for estimating the model parameters from data and presents a validation algorithm for testing the model's goodness of fit. The paper demonstrates the effectiveness of ANM in several applications, including a gene regulatory network, a protein signaling pathway, and a benchmark model. The proposed method is suitable for analyzing complex systems with non-Gaussian and correlated errors, making it a useful tool for various fields.

#### Example: What causal direction better explains the data ? X → Y or Y → X ?

![image](https://user-images.githubusercontent.com/109908559/223644248-e072e68c-5d0b-4b22-81cf-39ab7871c055.png)

#### Causal recovery with ANM

### Data

- Try to design the problem of different by a graph with specific directed edges if there is a causality or not
- See the different correlations on pair plots (data viz, statistical tables, boxplots)
- Translate these coreelations to a 0-1 score that indicates if there is really a correlation between 

- recover causal directions in causal pairs, and on triplets if we have time
- larger graphs and quantitative evaluations
- 
