---
layout: post
title: Modeling and optimization of discrete systems
---

*Simplex algorithm* : The simplex algorithm is a method for solving linear programming problems. It starts with an initial feasible solution and then iteratively  moves to other solutions that are better (i.e., have higher or lower objective function values) until it finds the optimal solution or proves that none exists. The algorithm works by finding the direction in which the objective function can be improved the most and then moving in that direction as far as possible while still remaining feasible. At each iteration, it selects one of the variables to be the "pivot" and re-organizes the constraints and objective function in order to move to the next solution. The process continues until the objective function can no longer be improved or an unbounded solution is found.

### Introduction to Linear Programming

Move from one vertex of the polyhedron to an adjacent vertex, increasing the value of the objective function, until you find thevertex with the maximum value.

1. Formulate the problem in a system of linear equations.
2. Transform it into the standard by adding slack variables that represents the difference between the inequality & the equality.
3. Represent as a canonical tableau

Suppose we have the following linear program in standard form:

maximize $z = 2x_1 + 3x_2$

subject to:

$3x_1 + 2x_2 \leq 18$

$2x_1 + 1x_2 \leq 10$

$x_1, x_2 \geq 0$

We can represent the simplex tableau as follows:

$$\begin{array}{|c|c|c|c|c|c|} \hline
& x_1 & x_2 & s_1 & s_2 & \text{RHS} \\ 
\hline
s_1 & 3 & 2 & 1 & 0 & 18 \\
s_2 & 2 & 1 & 0 & 1 & 10 \\
z & -2 & -3 & 0 & 0 & 0 \\
\hline
\end{array}$$

The first row represents the coefficients of the first constraint, with $s_1$ representing the slack variable. The second row represents the coefficients of the second constraint, with $s_2$ representing the slack variable. The third row represents the coefficients of the objective function. The columns represent the variables and the slack variables, and the right-hand column represents the values of the constraints and the objective function.

To perform the simplex method, we first choose the most negative coefficient in the bottom row, which is $-3$. We select the column for $x_2$, since it corresponds to the most negative coefficient. We then calculate the ratios of the right-hand column to the selected column, which gives us:

$$\begin{array}{|c|c|c|c|c|c|}
\hline
& x_1 & x_2 & s_1 & s_2 & \text{RHS} \\
\hline
s_1 & 3/2 & 1 & 1/2 & 0 & 9 \\
s_2 & 1/2 & 1 & -1/2 & 1 & 5 \\
z & 1/2 & 0 & 3/2 & 0 & 15 \\
\hline
\end{array}$$

We pivot on the intersection of the row for $s_1$ and the column for $x_2$, which is the entry $2$. This gives us the following tableau:

$$\begin{array}{|c|c|c|c|c|c|}
\hline
& x_1 & x_2 & s_1 & s_2 & \text{RHS} \\
\hline
x_2 & \frac{3}{4} & 0 & \frac{1}{4} & 0 & \frac{9}{2} \\
s_2 & \frac{1}{4} & 1 & -\frac{1}{4} & 1 & \frac{7}{2} \\
z & \frac{5}{4} & 0 & \frac{3}{4} & 0 & \frac{27}{2} \\
\hline
\end{array}$$

Since there are no negative coefficients in the bottom row, we have found the optimal solution. The solution is $x_1 = 0$, $x_2 = 9/2$, and $z = 27/2$.

#### Pivot rule

The pivot rule is a method used in linear programming to solve a system of linear equations by converting it into a standard form known as the canonical form. The pivot rule involves selecting a pivot element (usually the element with the largest absolute value) from the objective function or a constraint and using it as the basis for the next iteration of the simplex algorithm. This process is repeated until the optimal solution is found or it is determined that no solution exists.

Initial solutions => feasible solutions 
Artificial variables (same as slack variables? ) $\to 0$

#### Two phases method

$$\operatorname{min} e^T x_ a$$
$$A x + x_ a = b$$
$$x, x_ a ≥ 0$$

If $x_ a \neq 0$ for the solution, then there is no feasible solution.
Else, the solution of the first phase is the basic feasible solution for the second phase.

The two-phase method is a technique used to solve linear programming problems that have degenerate solutions, which means that some of the constraints are met with equality and there are non-basic variables that have zero values. In the first phase of the method, an artificial variable is introduced for each equality constraint and the objective function is modified so that it becomes a minimization problem with a non-negative objective function. The goal is to make all artificial variables zero in a feasible solution, at the same time find a feasible solution for the original problem. In the second phase, the original objective function is restored and the artificial variables are removed, this phase is to find the optimal solution of the original problem with the feasible solution obtained in the first phase. The two-phase method is guaranteed to find a feasible and optimal solution if one exists.

#### Big M method

The Big M method is a technique used to convert certain types of constraints in a linear programming problem into a standard form that can be solved using simplex method. It is used to handle constraints that are not in the standard form of "less than or equal to" or "greater than or equal to" a constant.

The basic idea of the Big M method is to introduce a new variable called a "surrogate variable" or "slack variable" (in this case x_a) and to add the constraint: $x_ a \leq M$
Where M is a large positive number called the "Big M".

The original constraint is then replaced by a set of two constraints, one that represents the original constraint but with the "surrogate variable" x_a, and another that represents the new constraint. For example, if the original constraint is of the form "greater than or equal to": $Ax \geq b$
$$\operatorname{min} c^T x + Me^T x_ a$$
$$A x + x_ a = b$$
$$x, x_ a ≥ 0$$
$Me^T x_ a$ is a kind of penalty for anysolution where $x_a \neq 0$

#### Degenerescence

A linear program is non-degenerated iff the basic variables of any feasible solution are non-negative. Therefore, input variables may to be non-negative.

## Duality, main concept in linear programming

It gives the *proof of optimality* not only on the *algorithmic level* but also in *combinatorics*

"Duality in linear programming refers to the relationship between the primal problem, which is the original optimization problem to be solved, and the dual problem, which is derived from the primal problem. The primal problem is typically a maximization or minimization of a linear objective function subject to a set of linear constraints, while the dual problem is the maximization or minimization of a linear objective function subject to a set of constraints that are derived from the primal problem's constraints. The solution of the primal problem can be used to find the solution of the dual problem and vice versa. The concept of duality is used to provide alternative ways to solve a linear programming problem and can also be used to provide insight into the structure of the problem."

### Feasible linear program : Farkas lemma

Let us consider the linear system $Ax = b$, $x ≥ 0$, then one and only one of the following systems has a solution :
1. $\exists x$, $Ax = b, x ≥ 0.$
2. $\exists y$, $A^T y ≥ 0$ and $y$ such that, $y^T b < 0.$

*The duality is motivated by the search for lower bounds of the optimal solution*

$$\operatorname{min} c^T x$$
$$Ax = b, x ≥ 0 $$

To have the best lower bound, we can multiply each equation $A_ m x =b_ m$ by a number $y$ et compute the sum of the system $y^T Ax =y^T b$ and solve:

$$\operatorname{max} b^T y$$
$$ A^T y \leq c$$

And we get the *dual* program of the first that is called the *primal*. These solution gives the lower bound of the primal. $P$ is a minimization problem and $D$ a maximization...

*Week duality* : If we denote $z = \operatorname{min}c^T x$ the optimal of the primal and $w=\operatorname{max} b^T y$ optimal of the dual, then $w \leq z$
*The dual of dual is the primal*

$$c^T x ≥ y^T Ax = y^T b$$
Because $z = \operatorname{min} \{ c^T x : Ax = b, x ≥ 0 \} ≥ \operatorname{max} \{ b^T y : A^T y ≤ c \} = w$

*Strong duality*: If primal or dual is feasible, then $z=w$. (with any other assumption)

### Conditions of complementarity

*Duality gap* the difference between $z= \operatorname{min} \{ c^T x : Ax = b, x ≥ 0 \}$ of primal and $w =\operatorname{max} \{ b^T y : A^T y ≤ c \}$ of dual. Let $x,y$ optimal solutions then duality gap is equal to $0$. If one of the two is feasible, it is optimal and the other too.

#### Definitions

*Objective Function*:    The function that is either being minimized or maximized. For example, it may represent the cost that you are trying to minimize. 

*Optimal Solution*: A vector x which is both feasible (satisfying the constraints) and optimal (obtaining the largest or smallest objective value). 

*Constraints*
    A set of equalities and inequalities that the feasible solution must satisfy. 

*Feasible Solution*
    A solution vector, x, which satisfies the constraints. 

*Basic Solution*
    $x$ of ($Ax=b$) is a basic solution if the $n$ components of $x$ can be partitioned into $m$ "basic" and $n-m$ "non-basic" variables in such a way that:
    the m columns of A corresponding to the basic variables form a nonsingular basis and
    the value of each "non-basic" variable is $0$.

The *constraint matrix* $A$ has $m$ rows (constraints) and $n$ columns (variables).

*Basis*
    The set of basic variables. 

*Basic Variables*
    A variable in the basic solution (value is not $0$). 

*Nonbasic Variables*
    A variable not in the basic solution (value $= 0$). 

*Slack Variable*
    A variable added to the problem to eliminate less-than constraints. 

*Surplus Variable*
    A variable added to the problem to eliminate greater-than constraints. 

*Artificial Variable*
    A variable added to a linear program in phase 1 to aid finding a feasible solution. 

*Unbounded Solution*
    For some linear programs it is possible to make the objective arbitrarily small (without bound). Such an LP is said to have an unbounded solution.

Integer linear programming

We consider the following problem *only with integer variables*

$$\operatorname{min} c^T x$$
$$Ax = b, x ≥ 0 $$

Examples of problems: assignment, knapsack, Travelling Salesman Problem, simple plant location


